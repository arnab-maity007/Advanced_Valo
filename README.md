# ğŸ® Advanced Valorant AI Commentary System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![ElevenLabs](https://img.shields.io/badge/ElevenLabs-TTS-green.svg)](https://elevenlabs.io)
[![OpenCV](https://img.shields.io/badge/OpenCV-Computer_Vision-red.svg)](https://opencv.org)
[![Node.js](https://img.shields.io/badge/Node.js-Backend-brightgreen.svg)](https://nodejs.org)

**Professional AI-powered eSports commentary system for Valorant gameplay analysis with real-time event detection and high-quality voice synthesis.**

## ğŸŒŸ Key Features

### ğŸ¯ **Agent Selection Commentary**
- **Dual-Caster System**: Hype and Analyst commentary styles
- **Fuzzy Agent Recognition**: Detects 25+ Valorant agents
- **Lock-in Detection**: Real-time agent selection tracking
- **Strategic Analysis**: Team composition insights

### ğŸ’° **Buy Phase Analysis**  
- **Economic Intelligence**: Advanced purchase pattern analysis
- **OCR Integration**: Multi-engine text extraction (EasyOCR + Tesseract)
- **Weapon Classification**: Intelligent item categorization
- **Status Detection**: Owned/Requesting/Hovering states
- **Team Coordination**: Purchase synchronization analysis

### ğŸ® **Enhanced Gameplay Commentary** â­ NEW!
- **Event-Driven Detection**: 430+ events per video
- **Kill Feed Analysis**: Real-time elimination tracking
- **Ability Recognition**: Tactical play detection
- **Round Phase Tracking**: Prep/Action/Post-round identification
- **Scoreboard Analysis**: Live score and round monitoring
- **Tactical Events**: Spike plant/defuse recognition

### ğŸ¤ **Professional Voice Synthesis**
- **Multiple Voices**: 6+ ElevenLabs voice options
- **Commentary Styles**: Play-by-play, Analysis, Excitement, Educational
- **High-Quality Audio**: Broadcast-level MP3 output
- **Interactive Players**: HTML audio interfaces
- **Perfect Synchronization**: Frame-accurate timing

### ğŸŒ **Modern Web Platform**
- **Valorant-Themed UI**: Professional gaming aesthetic
- **Real-time Communication**: Socket.io integration
- **MongoDB Backend**: Scalable data storage
- **Responsive Design**: Cross-device compatibility

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/arnab-maity007/Advanced_Valo.git
cd Advanced_Valo

# Install dependencies
pip install -r requirements.txt

# Generate commentary (with voice)
python voice_commentary_generator.py

# Enhanced gameplay analysis  
python enhanced_gameplay_commentator.py

# Voice selection
python voice_selector.py
```

## ğŸ“Š System Performance

| Feature | Agent Selection | Buy Phase | Gameplay Rounds |
|---------|----------------|-----------|-----------------|
| **Detection Accuracy** | 95%+ | 90%+ | 85%+ |
| **Commentary Quality** | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ |
| **Voice Synthesis** | âœ… Professional | âœ… Professional | âœ… Professional |
| **Events Detected** | Agent hover/lock | Purchases/requests | 430+ per video |

## ğŸ”§ Technologies

- **AI/ML**: OpenCV, YOLO, EasyOCR, Custom Classification
- **Voice**: ElevenLabs TTS API (6+ professional voices)
- **Backend**: Node.js, Express, MongoDB, Socket.io
- **Frontend**: Modern HTML/CSS/JS with Valorant theming

## How It Works

The system operates in a multi-stage pipeline:

1.  **Detection**: A trained object detection model (either a cloud-based model from Roboflow or a local YOLO model) scans the game screen (from an image or video frame) to identify key UI elements, referred to as "event-boxes".

2.  **OCR and Text Extraction**: Once an event-box is detected, the system crops that specific region of the image. Advanced image preprocessing techniques are applied, and then OCR is used to extract any text within the box, such as weapon names, prices, or ability statuses.

3.  **Classification and Structuring**:

      * **Buy Phase**: The extracted text from the buy menu is processed by a classifier that uses fuzzy string matching and regular expressions to identify the specific item (e.g., "Vandal", "Heavy Shields") and its status (e.g., `weapon_owned`, `requesting_weapon`). This structured data is then saved to a JSON file.
      * **Agent Selection**: The system identifies the agent's name and looks for the "LOCK IN" button to determine if a player is just considering an agent or has confirmed their choice. This state is also saved.

4.  **Commentary Generation**: The JSON files containing the structured data act as triggers for the commentary engine. The system reads the latest events and:

      * Prioritizes the most important actions.
      * Selects a caster role (alternating between Hype and Analyst).
      * Chooses a suitable commentary template for the event.
      * Fills in the template with the relevant details (player name, weapon, etc.) to generate a final line of commentary.

## Repository Structure

```
.
â”œâ”€â”€ agents/                  # Sample images from the Agent Selection phase
â”œâ”€â”€ buyphase/                # Sample images from the Buy Phase
â”œâ”€â”€ results/                 # Output directory for annotated images and JSON results
â”œâ”€â”€ Output Processed Json/   # Contains the core logic for commentary and JSON processing
â”‚   â”œâ”€â”€ agent.json           # Example processed data for agent selection
â”‚   â”œâ”€â”€ buy.json             # Example processed data for the buy phase
â”‚   â”œâ”€â”€ agentprocessor.py    # Generates commentary for agent selection
â”‚   â””â”€â”€ buycommentary.py     # Generates commentary for the buy phase
â”œâ”€â”€ buy_phase.py             # Main script for processing the buy phase using Roboflow API
â”œâ”€â”€ buyphase.py              # Main script for processing the buy phase using a local YOLO model
â”œâ”€â”€ model.py                 # Main script for processing agent selection
â”œâ”€â”€ shower.py                # Enhanced OCR script with a preview window for verification
â”œâ”€â”€ requirements.txt         # Project dependencies
â””â”€â”€ ...                      # Other scripts and data files
```

## Setup and Usage

### Prerequisites

  * Python 3.x
  * Tesseract OCR Engine
  * API keys for Roboflow and Riot Games (optional, for full functionality)

### Installation

1.  **Clone the repository:**

    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Install Python dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure Tesseract OCR:**

      * Make sure Tesseract is installed and accessible from your system's PATH.
      * Alternatively, you can specify the path to the Tesseract executable directly in the scripts (e.g., in `imp.txt` or at the top of `ocr.py`).

4.  **Set API Keys:**

      * For scripts using the Roboflow or Riot Games API, set your API keys as environment variables or replace the placeholder keys in the code.

### Running the System

You can run the different modules of the system individually. The general workflow is to first process images/videos to generate JSON data, and then use that data to generate commentary.

1.  **Process Buy Phase Images:**

      * To process a folder of images and generate detection results:
        ```bash
        python buy_phase.py
        ```
        (Follow the interactive prompts to select the folder and options)

2.  **Run OCR on Detections:**

      * After generating detection JSON, run the OCR script to extract text. The `shower.py` script is recommended as it provides a visual preview to verify accuracy.

3.  **Generate Commentary:**

      * Once you have processed JSON files (e.g., `buy.json`), you can run the commentary scripts:
        ```bash
        # For buy phase commentary
        python "Output Processed Json/buycommentary.py"

        # For agent selection commentary
        python "Output Processed Json/agentprocessor.py"
        ```

## Key Dependencies

  * `ultralytics`: For running the YOLO model.
  * `opencv-python`: For image and video processing.
  * `numpy`: For numerical operations.
  * `torch`: The backend for the YOLO model.
  * `pytesseract` & `easyocr`: For Optical Character Recognition.
  * `requests`: For making API calls.
  * `fuzzywuzzy`: For string matching in the classification scripts.
